{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from typing import Text, Dict, List\n",
    "import tqdm\n",
    "import logging\n",
    "from privatecog_suggestions.utils import get_intent_code_mapping\n",
    "\n",
    "logger = logging.getLogger()\n",
    "\n",
    "_SESSION_LAPSES_MIN = [1, 2, 5, 10, 30, 60]\n",
    "_NUM_MAX_INTENTS_PER_DOMAIN = 20\n",
    "INTENT_CODES = get_intent_code_mapping()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def _get_domain(intent_name: Text) -> Text:\n",
    "    \"\"\"\n",
    "    Get the domain name from an intent name\n",
    "    \"\"\"\n",
    "    if \".\" not in intent_name:\n",
    "        return intent_name\n",
    "    return intent_name[:intent_name.index(\".\")]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RecognizerLogsFormatter(object):\n",
    "\n",
    "    def __init__(self, session_lapses_min: List[int] = _SESSION_LAPSES_MIN):\n",
    "        \"\"\"\n",
    "        :param session_lapses_min: List of lapses in minutes to group requests into the same session.\n",
    "        \"\"\"\n",
    "        self.session_lapses_min = session_lapses_min\n",
    "\n",
    "    def format_logs(self, file_path: Text, output_path: Text = None, output_format=\"csv\", run_in_notebook=False,\n",
    "                    translation_dict: Dict[Text, int] = INTENT_CODES) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Format a Recognizer logs file into a pandas Dataframe.\n",
    "        :param file_path:\n",
    "        :param output_path: path to save the formatted data.\n",
    "        :param output_format: Possible values: \"csv\"|\"pick\"\n",
    "        :param run_in_notebook: True if this method is intended to be called within a jupyter notebook. False\n",
    "        otherwise.\n",
    "        :return Pandas Dataframe\n",
    "        \"\"\"\n",
    "        df = pd.read_csv(file_path)\n",
    "\n",
    "        # To numeric categorical values...\n",
    "        df[\"n_USER_ID\"] = df[\"USER_ID\"].astype(\"category\").cat.codes.apply(lambda x: float(x))\n",
    "        df[\"n_USER_ID_GLOBAL\"] = df[\"USER_ID_GLOBAL\"].astype(\"category\").cat.codes.apply(lambda x: float(x))\n",
    "        # Convert dates\n",
    "        df[\"RECOGNIZER_DT\"] = pd.to_datetime(df[\"RECOGNIZER_DT\"])\n",
    "        # Change UTC time to Spain/Madrid UTC time\n",
    "        df['RECOGNIZER_DT_CONVERT'] = df['RECOGNIZER_DT'].dt.tz_convert(tz='Europe/Madrid')\n",
    "        # Build numerical timestamps\n",
    "        df[\"TIMESTAMP\"] = df['RECOGNIZER_DT_CONVERT'].values.astype(np.int64)\n",
    "        # Add auxiliary ones column to make counts easier\n",
    "        df[\"__ONES\"] = np.ones((len(df)))\n",
    "        # Add domain column\n",
    "        df[\"DOMAIN\"] = df[\"INTENT\"].apply(lambda s: _get_domain(str(s)))\n",
    "        # Convert dates\n",
    "        # df[\"RECOGNIZER_DT\"] = pd.to_datetime(df[\"RECOGNIZER_DT\"])\n",
    "\n",
    "        # Encode intents\n",
    "        intent_encoder = IntentEncoder(df, translation_dict=translation_dict)\n",
    "        df[\"INTENT_ENCODED\"] = df.INTENT.apply(\n",
    "            lambda s: intent_encoder.encode_intent(str(s)))\n",
    "\n",
    "        # Order by date\n",
    "        df = df.sort_values(by=[\"RECOGNIZER_DT_CONVERT\"])\n",
    "\n",
    "        # Add sessions data\n",
    "        for lapse in self.session_lapses_min:\n",
    "            df[\"SESSION_{}_MIN\".format(lapse)] = np.ones(len(df)) * -1\n",
    "\n",
    "        df_grouped_by_private_id = df.groupby(\"USER_ID_GLOBAL\")\n",
    "        if run_in_notebook:\n",
    "            _tqdm = tqdm.tqdm_notebook\n",
    "        else:\n",
    "            _tqdm = tqdm.tqdm\n",
    "        for g_name, _df in _tqdm(df_grouped_by_private_id):\n",
    "            for lapse in self.session_lapses_min:\n",
    "                sessions = self._get_sessions_per_user(_df, lapse * 60)\n",
    "                indices = _df.index\n",
    "                for i, s in enumerate(sessions):\n",
    "                    df.at[indices[i], \"SESSION_{}_MIN\".format(lapse)] = s\n",
    "\n",
    "        # Save dataframe\n",
    "        if output_path is not None:\n",
    "            if output_format.lower() == \"csv\":\n",
    "                df.to_csv(output_path)\n",
    "            elif output_format.lower() in {\"pick\", \"pickle\"}:\n",
    "                df.to_pickle(output_path)\n",
    "            else:\n",
    "                raise Exception(\"Wrong value for argument 'output_format': {}. Valid values are 'csv' | 'pick'\".format(\n",
    "                    output_format))\n",
    "        return df\n",
    "\n",
    "    def _get_sessions_per_user(self, df: pd.DataFrame, max_seconds: float = 1 * 60) -> List[int]:\n",
    "        \"\"\"\n",
    "        Get an array of indexes to group related entries. Related entries are those whose time difference is\n",
    "        less than or equal to max_seconds.\n",
    "        :param df:\n",
    "        :param max_seconds:\n",
    "        :return\n",
    "        \"\"\"\n",
    "        max_nano_seconds = max_seconds * 1e09\n",
    "        _counter = 0\n",
    "        res = []\n",
    "        diff = df[\"TIMESTAMP\"].diff()\n",
    "        for v in diff.values:\n",
    "            if v > max_nano_seconds:\n",
    "                _counter += 1\n",
    "            res.append(_counter)\n",
    "        return res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IntentEncoder(object):\n",
    "    \"\"\"\n",
    "    This class encodes intent names into numerical values.\n",
    "    The translation dictionary can be retrieved (if not specify in constructor) from translation_dict.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, df: pd.DataFrame, translation_dict: Dict[Text, int] = None,\n",
    "                 num_max_intents_per_domain=_NUM_MAX_INTENTS_PER_DOMAIN):\n",
    "        \"\"\"\n",
    "        :param df:\n",
    "        :param translation_dict: Dictionary used for translation (intent_name -> numerical_value)\n",
    "        :param num_max_intents_per_domain\n",
    "        \"\"\"\n",
    "        self.num_max_intents_per_domain = num_max_intents_per_domain\n",
    "        # Sorted domains\n",
    "        self.domains = sorted(df.DOMAIN.unique())\n",
    "        # Dictionary of related (ordered) intents grouped by domain\n",
    "        self.intents_dict = {}\n",
    "        for intent in df.DOMAIN.unique():\n",
    "            self.intents_dict[intent] = sorted(df[df.DOMAIN == intent].INTENT.unique())\n",
    "\n",
    "        if translation_dict is not None:\n",
    "            self.translation_dict = translation_dict\n",
    "        else:\n",
    "            # Build translation dictionary\n",
    "            self.translation_dict = {}\n",
    "            for domain, intent_list in self.intents_dict.items():\n",
    "                for intent in intent_list:\n",
    "                    self.translation_dict[intent] = self.domains.index(domain) * self.num_max_intents_per_domain + \\\n",
    "                                                    self.intents_dict[domain].index(intent) + 1\n",
    "\n",
    "        logger.info(\"Intent translation dictionary: {}\".format(self.translation_dict))\n",
    "        # print(\"Intents dict:\")  # Debug\n",
    "        # pprint.pprint(self.intents_dict)  # Debug\n",
    "        # print(\"Intents translation dict:\")  # Debug\n",
    "        # pprint.pprint(self.translation_dict)  # Debug\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_intent(self, intent_name: str):\n",
    "    \"\"\"\n",
    "    Assigns a numeric value to an intent name\n",
    "    \"\"\"\n",
    "    return self.translation_dict.get(intent_name, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST\n",
    "# TODO: move to unitary test\n",
    "if __name__ == \"__main__\":\n",
    "    file_path = \"data/RECOGNIZER-NLP-201812.csv\"\n",
    "    output_path = \"/tmp/formatted.csv\"\n",
    "\n",
    "    formatter = RecognizerLogsFormatter()\n",
    "    df = formatter.format_logs(file_path, output_path=output_path, output_format=\"csv\", run_in_notebook=False)\n",
    "\n",
    "    print(df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Kikenv",
   "language": "python",
   "name": "kikenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
