{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training a Multiclass Classifier\n",
    "\n",
    "Construct a feedforward NN with an output layer with softmax activations function.\n",
    "\n",
    "- 1-. Data is 11228 reuters newswires. Each newswire is categorized into 46 topics. We have converted those newswire into 5000 binary features. (denoting the presence of certain word in the newswire).Prepare the target data with one-hot encoding so that we obtain a target matrix denoting which of the 46 classes an observation belongs to.\n",
    "\n",
    "- 2-. Secondly we increased the nu,ber of units ineach hidden layers to help the NN represent the more complex relationships between 46 classes.\n",
    "\n",
    "- 3-. Output layer with 46 units (one per class) containing a softmax activation function, will return an array of 46 values summing to 1. This 46 values represent an observation's probability of being a member of each of the 46 classes.\n",
    "\n",
    "- 4-. We use a loss function suited to multiclass classification, the categorical cross entropy loss function.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load libraries\n",
    "\n",
    "import numpy as np\n",
    "from keras import models\n",
    "from keras import layers\n",
    "from keras.datasets import reuters\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.preprocessing.text import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create random seed\n",
    "\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create number of features\n",
    "\n",
    "number_features = 5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://s3.amazonaws.com/text-datasets/reuters.npz\n",
      "2113536/2110848 [==============================] - 1s 1us/step\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "\n",
    "data = reuters.load_data(num_words = number_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create train and target \n",
    "\n",
    "\n",
    "(data_train, target_vector_train) , (data_test, target_vector_test) = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert feature data to a one-hot encoded feature matrix\n",
    "\n",
    "tokenizer = Tokenizer(num_words = number_features)\n",
    "\n",
    "features_train = tokenizer.sequences_to_matrix(data_train, mode = \"binary\")\n",
    "\n",
    "features_test = tokenizer.sequences_to_matrix(data_test, mode = \"binary\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot encode target vector ro create a target matrix\n",
    "\n",
    "target_train = to_categorical(target_vector_train)\n",
    "\n",
    "target_test = to_categorical(target_vector_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start NN\n",
    "\n",
    "network = models.Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add fully connected layer with a reLU activation function\n",
    "\n",
    "network.add(layers.Dense(units = 100, activation = \"relu\", input_shape = (number_features,)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add fully connected layer with relu activation fucntion\n",
    "\n",
    "network.add(layers.Dense(units=100, activation = \"relu\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add fully connected layer with softmax activation function\n",
    "\n",
    "network.add(layers.Dense(units=46, activation = \"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile Neural Network\n",
    "\n",
    "network.compile(loss = \"categorical_crossentropy\", optimizer = \"rmsprop\", metrics = [\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8982 samples, validate on 2246 samples\n",
      "Epoch 1/10\n",
      "8982/8982 [==============================] - 1s 110us/step - loss: 0.3571 - accuracy: 0.9202 - val_loss: 0.8901 - val_accuracy: 0.8050\n",
      "Epoch 2/10\n",
      "8982/8982 [==============================] - 1s 106us/step - loss: 0.2723 - accuracy: 0.9359 - val_loss: 0.9260 - val_accuracy: 0.8014\n",
      "Epoch 3/10\n",
      "8982/8982 [==============================] - 1s 109us/step - loss: 0.2236 - accuracy: 0.9469 - val_loss: 1.0331 - val_accuracy: 0.7841\n",
      "Epoch 4/10\n",
      "8982/8982 [==============================] - 1s 122us/step - loss: 0.1914 - accuracy: 0.9495 - val_loss: 1.0785 - val_accuracy: 0.7827\n",
      "Epoch 5/10\n",
      "8982/8982 [==============================] - 1s 112us/step - loss: 0.1744 - accuracy: 0.9505 - val_loss: 1.0714 - val_accuracy: 0.7965\n",
      "Epoch 6/10\n",
      "8982/8982 [==============================] - 1s 119us/step - loss: 0.1630 - accuracy: 0.9505 - val_loss: 1.1222 - val_accuracy: 0.7921\n",
      "Epoch 7/10\n",
      "8982/8982 [==============================] - 1s 110us/step - loss: 0.1523 - accuracy: 0.9528 - val_loss: 1.1874 - val_accuracy: 0.7890\n",
      "Epoch 8/10\n",
      "8982/8982 [==============================] - 1s 115us/step - loss: 0.1465 - accuracy: 0.9534 - val_loss: 1.1664 - val_accuracy: 0.7943\n",
      "Epoch 9/10\n",
      "8982/8982 [==============================] - 1s 120us/step - loss: 0.1388 - accuracy: 0.9528 - val_loss: 1.2341 - val_accuracy: 0.7898\n",
      "Epoch 10/10\n",
      "8982/8982 [==============================] - 1s 116us/step - loss: 0.1309 - accuracy: 0.9555 - val_loss: 1.3277 - val_accuracy: 0.7894\n"
     ]
    }
   ],
   "source": [
    "# Train Neural Network\n",
    "\n",
    "history = network.fit(features_train, target_train, epochs = 10, verbose = 1, batch_size = 100, validation_data = (features_test, target_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View target matrix\n",
    "\n",
    "target_train"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Kikenv",
   "language": "python",
   "name": "kikenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
