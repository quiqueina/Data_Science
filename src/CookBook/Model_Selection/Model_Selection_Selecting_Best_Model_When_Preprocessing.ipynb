{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Selecting Best Model When Preprocessing.\n",
    "\n",
    "Include preprocessing with their own parameters.\n",
    "\n",
    "# Feature Union\n",
    "\n",
    "Allows us to create a pipeline to combine multiple preprocessing actions properly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load libraries\n",
    "\n",
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set Random Seed \n",
    "\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "\n",
    "# Create Feature matrix and target vector\n",
    "\n",
    "features = iris.data\n",
    "target = iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Preprocessing object that includes StandardScaler, features and PCA\n",
    "\n",
    "preprocess = FeatureUnion([(\"std\", StandardScaler()), (\"pca\", PCA())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([(\"preprocess\", preprocess),\n",
    "                 (\"classifier\", LogisticRegression(max_iter = 1000, solver = \"liblinear\"))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some preprocessing methods have their own parameters, which often have to be supplied by the user.\n",
    "\n",
    "Scikit Learn make this easy by introducing candidates component values in the search space. They are treated as any other hyperparameter to be seached over.\n",
    "\n",
    "features__n__components : [1,2,3] to discover if 1,2 or 3 is the best option to Principal Components (PCA)\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'preprocess__pca__n_components': [1, 2, 3],\n",
       "  'classifier__penalty': ['l1', 'l2'],\n",
       "  'classifier__C': array([1.00000000e+00, 2.78255940e+00, 7.74263683e+00, 2.15443469e+01,\n",
       "         5.99484250e+01, 1.66810054e+02, 4.64158883e+02, 1.29154967e+03,\n",
       "         3.59381366e+03, 1.00000000e+04])}]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create space of candidates values \n",
    "\n",
    "search_space = [{\"preprocess__pca__n_components\": [1,2,3],\n",
    "                 \"classifier__penalty\":[\"l1\", \"l2\"],\n",
    "                 \"classifier__C\": np.logspace(0,4,10)}]\n",
    "\n",
    "# Dictionary for Random Forest Hyperparameters\n",
    "\n",
    "search_space"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grid Search uses Cross Validation to determine which model has the highest performance. However, we cant preprocess data and run Grid Search. Thats why we are using FeatureUnion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score=nan,\n",
       "             estimator=Pipeline(memory=None,\n",
       "                                steps=[('preprocess',\n",
       "                                        FeatureUnion(n_jobs=None,\n",
       "                                                     transformer_list=[('std',\n",
       "                                                                        StandardScaler(copy=True,\n",
       "                                                                                       with_mean=True,\n",
       "                                                                                       with_std=True)),\n",
       "                                                                       ('pca',\n",
       "                                                                        PCA(copy=True,\n",
       "                                                                            iterated_power='auto',\n",
       "                                                                            n_components=None,\n",
       "                                                                            random_state=None,\n",
       "                                                                            svd_solver='auto',\n",
       "                                                                            tol=0.0,\n",
       "                                                                            whiten=False))],\n",
       "                                                     transformer_weights=None,\n",
       "                                                     verbose=Fals...\n",
       "             iid='deprecated', n_jobs=None,\n",
       "             param_grid=[{'classifier__C': array([1.00000000e+00, 2.78255940e+00, 7.74263683e+00, 2.15443469e+01,\n",
       "       5.99484250e+01, 1.66810054e+02, 4.64158883e+02, 1.29154967e+03,\n",
       "       3.59381366e+03, 1.00000000e+04]),\n",
       "                          'classifier__penalty': ['l1', 'l2'],\n",
       "                          'preprocess__pca__n_components': [1, 2, 3]}],\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=0)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create GridSearch\n",
    "\n",
    "gridsearch = GridSearchCV(pipe, search_space, cv=5, verbose=0)\n",
    "gridsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit Grid Search\n",
    "\n",
    "best_model = gridsearch.fit(features,target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After the search is completed we can use best_estimator_ to view best model's learning algorithm and hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Model:  1\n"
     ]
    }
   ],
   "source": [
    "# See the hyperparameters of the best model\n",
    "\n",
    "print(\"Best Model: \", best_model.best_estimator_.get_params()[\"preprocess__pca__n_components\"])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Kikenv",
   "language": "python",
   "name": "kikenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
