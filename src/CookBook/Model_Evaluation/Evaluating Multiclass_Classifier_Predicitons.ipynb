{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating Multiclass Classifier Predictions\n",
    "\n",
    "You have a model that predicts three or more classes and want to evaluate its performance.\n",
    "\n",
    "Using cross validation with an evaluation metric of handling more than two clasess."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load librariesfrom \n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.datasets import make_classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate features matrix and target vector\n",
    "\n",
    "features, target = make_classification(n_samples=10000,\n",
    "                                      n_features= 3,\n",
    "                                      n_informative = 3,\n",
    "                                      n_redundant = 0, \n",
    "                                      n_classes = 3,\n",
    "                                      random_state = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Logistic Regression\n",
    "\n",
    "logit = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.841 , 0.829 , 0.8265, 0.8155, 0.82  ])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cross Validatemodel using accuracy\n",
    "\n",
    "cross_val_score(logit, features, target, scoring = \"accuracy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having balanced classes,  accuracy is an interpretable choice for evaluation.\n",
    "\n",
    "Accuracy is the number of correct predictions divided by the number of observations and works just as well in the multiclass as binary setting. \n",
    "\n",
    "Having imbalanced classes itś better to be inclined to use other evaluation metrics:\n",
    "\n",
    "Precision, Recall & F1-Score can be applied to multiclass settings by treating our data as a set of binary classes.\n",
    "\n",
    "Doing this allows us to apply the metrics to each class as if it were the only class in the data, and then aggregate the evaluation scores for all the classes by averaging them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.84061272, 0.82895312, 0.82625661, 0.81515121, 0.81992692])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cross Validatemodel using accuracy\n",
    "\n",
    "cross_val_score(logit, features, target, scoring = \"f1_macro\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Macro : Refers to the method used to average the evaluatuion scores from the classes.\n",
    "        Calculate mena of metric scores for each class, weighting each class equally.\n",
    "        \n",
    "Weightned : Calculate mena of metric scores for each class, weighting each class proportional to itś size in the data.\n",
    "    \n",
    "Micro: Calculate mena of metric scores for each observation-classcombination\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Kikenv",
   "language": "python",
   "name": "kikenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
