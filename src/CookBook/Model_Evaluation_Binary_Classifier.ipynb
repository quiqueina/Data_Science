{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODEL EVALUATION\n",
    "\n",
    "# EVALUATING BINARY CLASSIFIER PREDICTIONS\n",
    "\n",
    "Given a trained classification model you want to evaluate its quality."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance metrics\n",
    "\n",
    "### Scoring= \"accuracy\".\n",
    "\n",
    "Proportion of observations predicted correctly. In the real world data could suffer from imbalanced classes ( 90% women, 10% men) so that accuracy could suffers from a paradox where a model is highly accurate but lacks predictive power.\n",
    "\n",
    "Accuracy = (TP+TN)/(TP+TN+FP+FN)\n",
    "\n",
    "TP: True Positives. Predicted as True being True\n",
    "\n",
    "TN: True Negatives.  Predicted as False being False\n",
    "\n",
    "FP: False Positives. Predicted as True being False        ==> TYPE 1 ERROR \n",
    "\n",
    "FN: False Negatives. Predicted as False being True        ==> TYPE 2 ERROR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load libraries\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.datasets import make_classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Generate Feature Matrix and Target Vector \n",
    "\n",
    "X,y = make_classification(n_samples = 10000,\n",
    "                          n_features = 3,\n",
    "                          n_informative = 3,\n",
    "                          n_redundant = 0,\n",
    "                          n_classes = 2,\n",
    "                          random_state = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Logistic Regression\n",
    "\n",
    "logit = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.9555, 0.95  , 0.9585, 0.9555, 0.956 ])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cross Validate Model Using Accuracy\n",
    "\n",
    "cross_val_score(logit, X , y, scoring = \"accuracy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PRECISION\n",
    "\n",
    "Precision = TP / (TP*FP)\n",
    "\n",
    "Proportion of every observation predicted to be positive that is actually positive. It's similar to a measure of noise in our prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.95963673, 0.94820717, 0.9635996 , 0.96149949, 0.96060606])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cross Validate using precision\n",
    "\n",
    "cross_val_score(logit, X, y, scoring = \"precision\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RECALL\n",
    "\n",
    "Recall = TP / (TP + FN )\n",
    "\n",
    "Proportion of every positive observation that is truly positive. Recall measures the model's ability to identify an observation of the positive class.\n",
    "\n",
    "High recall models are optimistic in that they have a low bar for predicting thtat an obervation is in the positive class.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.951, 0.952, 0.953, 0.949, 0.951])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cross Validate using precision\n",
    "\n",
    "cross_val_score(logit, X, y, scoring = \"recall\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Kikenv",
   "language": "python",
   "name": "kikenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
